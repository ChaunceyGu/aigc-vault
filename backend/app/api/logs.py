"""
ç”Ÿæˆæ—¥å¿— API
å¤„ç†è®°å½•çš„åˆ›å»ºã€æŸ¥è¯¢ã€æ›´æ–°ã€åˆ é™¤
"""
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, Request
from fastapi.exceptions import RequestValidationError
from sqlalchemy.orm import Session
from sqlalchemy import desc
from typing import List, Optional, Union
import logging

from app.database import get_db
from app.models.gen_log import GenLog
from app.models.log_asset import LogAsset
from app.models.output_group import OutputGroup
from app.models.user import User
from app.services.rustfs_client import rustfs_client
from app.utils.image_processor import generate_thumbnail, validate_image
from app.utils.cache import cache
from app.utils.auth import require_permission, get_current_user_optional
from app.config import settings

logger = logging.getLogger(__name__)

router = APIRouter()


def get_proxy_url(file_key: str, size: str = None) -> str:
    """
    ç”Ÿæˆé€šè¿‡ API ä»£ç†çš„æ–‡ä»¶è®¿é—® URL
    è¿™æ ·å¤–ç½‘å¯ä»¥é€šè¿‡ web ç«¯å£è®¿é—®ï¼Œè€Œä¸éœ€è¦æš´éœ² RustFS ç«¯å£
    
    Args:
        file_key: æ–‡ä»¶æ ‡è¯†ç¬¦
        size: å›¾ç‰‡å°ºå¯¸ï¼Œå¯é€‰å€¼ï¼š'thumb'ï¼ˆç¼©ç•¥å›¾ï¼‰ã€'medium'ï¼ˆä¸­ç­‰å°ºå¯¸ï¼‰ã€Noneï¼ˆåŸå›¾ï¼‰
        
    Returns:
        é€šè¿‡ API ä»£ç†çš„ URL
    """
    from urllib.parse import quote
    # URL ç¼–ç  file_keyï¼Œç¡®ä¿ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚ /ã€% ç­‰ï¼‰è¢«æ­£ç¡®ç¼–ç 
    encoded_file_key = quote(file_key, safe='')
    url = f"/api/assets/{encoded_file_key}/stream"
    if size:
        url += f"?size={size}"
    return url


@router.post("/")
async def create_log(
    request: Request,
    title: str = Form(...),
    log_type: str = Form(...),
    prompt: Optional[str] = Form(None),
    params_note: Optional[str] = Form(None),
    is_nsfw: Optional[str] = Form(None, description="æ˜¯å¦ä¸ºNSFWå†…å®¹ï¼Œ'true' æˆ– 'false'"),
    input_files: List[UploadFile] = File(default=[]),
    input_notes: Optional[str] = Form(None, description="è¾“å…¥å›¾ç‰‡å¤‡æ³¨ï¼ŒJSON æ ¼å¼ï¼š{'filename1': 'note1', ...}"),
    output_groups: Optional[str] = Form(None, description="è¾“å‡ºç»„JSONï¼Œæ ¼å¼ï¼š[{'tools': ['tool1'], 'models': ['model1'], 'file_count': 2}, ...]ï¼Œæ–‡ä»¶æŒ‰ç»„é¡ºåºæ’åˆ—"),
    output_files: List[UploadFile] = File(default=[]),  # æ”¹ä¸ºå¯é€‰ï¼Œå› ä¸ºå¯èƒ½é€šè¿‡output_groupsä¼ é€’
    current_user: User = Depends(require_permission("log.create")),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°çš„ç”Ÿæˆè®°å½•
    
    - **title**: æ ‡é¢˜ï¼ˆå¿…å¡«ï¼‰
    - **log_type**: ç±»å‹ï¼Œ'txt2img' æˆ– 'img2img'ï¼ˆå¿…å¡«ï¼‰
    - **prompt**: æç¤ºè¯
    - **params_note**: å‚æ•°è®°å½•
    - **input_files**: è¾“å…¥å›¾ç‰‡ï¼ˆä»… img2img æ¨¡å¼éœ€è¦ï¼‰
    - **input_notes**: è¾“å…¥å›¾ç‰‡å¤‡æ³¨ï¼ŒJSON å­—ç¬¦ä¸²
    - **output_groups**: è¾“å‡ºç»„JSONï¼ˆå¿…å¡«ï¼‰ï¼Œæ¯ä¸ªç»„åŒ…å«å·¥å…·ã€æ¨¡å‹å’Œæ–‡ä»¶æ•°é‡
    - **output_files**: è¾“å‡ºå›¾ç‰‡ï¼ˆå¿…å¡«ï¼‰ï¼ŒæŒ‰ç»„çš„é¡ºåºæ’åˆ—
    """
    try:
        # éªŒè¯ç±»å‹
        if log_type not in ('txt2img', 'img2img'):
            raise HTTPException(status_code=400, detail="log_type å¿…é¡»æ˜¯ 'txt2img' æˆ– 'img2img'")
        
        # å¯¹äº txt2imgï¼Œå¿½ç•¥ input_filesï¼ˆå³ä½¿ä¼ é€’äº†ä¹Ÿå¿½ç•¥ï¼‰
        if log_type == 'txt2img':
            input_files = []
        
        # å¤„ç† input_filesï¼šè¿‡æ»¤æ‰æ— æ•ˆçš„æ–‡ä»¶å¯¹è±¡
        logger.info(f"ğŸ” æ¥æ”¶åˆ°çš„ input_files: ç±»å‹={type(input_files)}, æ˜¯å¦ä¸ºåˆ—è¡¨={isinstance(input_files, list)}, é•¿åº¦={len(input_files) if isinstance(input_files, list) else 'N/A'}")
        
        if input_files:
            logger.info(f"ğŸ“ input_files åˆ—è¡¨è¯¦æƒ…:")
            for i, f in enumerate(input_files):
                logger.info(f"  æ–‡ä»¶ {i}: ç±»å‹={type(f)}, filename={getattr(f, 'filename', 'N/A')}, size={getattr(f, 'size', 'N/A')}")
            
            # è¿‡æ»¤æ‰ä¸æ˜¯æœ‰æ•ˆ UploadFile çš„å¯¹è±¡
            # æ³¨æ„ï¼šUploadFile å®é™…ç±»å‹æ˜¯ starlette.datastructures.UploadFile
            valid_files = []
            for f in input_files:
                # æ£€æŸ¥æ˜¯å¦æœ‰ filename å±æ€§ï¼Œå¹¶ä¸” filename ä¸ä¸ºç©º
                # ä¸ä¾èµ– isinstance æ£€æŸ¥ï¼Œå› ä¸ºç±»å‹å¯èƒ½æ˜¯ starlette.datastructures.UploadFile
                filename = getattr(f, 'filename', None)
                if filename and filename.strip():
                    valid_files.append(f)
                    logger.info(f"âœ… æœ‰æ•ˆæ–‡ä»¶: {filename}")
                else:
                    logger.warning(f"âŒ è·³è¿‡æ— æ•ˆæ–‡ä»¶å¯¹è±¡: ç±»å‹={type(f)}, filename={filename}")
            input_files = valid_files
            logger.info(f"ğŸ“Š è¿‡æ»¤åçš„æœ‰æ•ˆæ–‡ä»¶æ•°é‡: {len(input_files)}")
        else:
            logger.warning(f"âš ï¸  input_files ä¸ºç©ºæˆ– None")
        
        # è§£æè¾“å‡ºç»„ï¼ˆJSON æ ¼å¼ï¼‰
        import json
        output_groups_list = []
        if output_groups:
            try:
                output_groups_list = json.loads(output_groups)
                if not isinstance(output_groups_list, list):
                    raise HTTPException(status_code=400, detail="output_groups å¿…é¡»æ˜¯æ•°ç»„æ ¼å¼")
            except json.JSONDecodeError as e:
                raise HTTPException(status_code=400, detail=f"æ— æ³•è§£æ output_groups JSON: {str(e)}")
        
        if not output_groups_list:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ä¸€ä¸ªè¾“å‡ºç»„")
        
        # éªŒè¯è¾“å‡ºç»„å’Œæ–‡ä»¶æ•°é‡æ˜¯å¦åŒ¹é…
        total_file_count = sum(group.get('file_count', 0) for group in output_groups_list)
        if len(output_files) != total_file_count:
            raise HTTPException(status_code=400, detail=f"è¾“å‡ºæ–‡ä»¶æ•°é‡ä¸åŒ¹é…ï¼šæœŸæœ› {total_file_count} ä¸ªæ–‡ä»¶ï¼Œå®é™… {len(output_files)} ä¸ª")
        
        # è§£æè¾“å…¥å¤‡æ³¨ï¼ˆJSON æ ¼å¼ï¼‰
        input_notes_dict = {}
        if input_notes:
            try:
                input_notes_dict = json.loads(input_notes)
            except json.JSONDecodeError:
                logger.warning(f"æ— æ³•è§£æ input_notes JSON: {input_notes}")
        
        # å¤„ç†is_nsfwå‚æ•°
        is_nsfw_value = 'false'
        if is_nsfw and is_nsfw.lower() == 'true':
            is_nsfw_value = 'true'
        
        # åˆ›å»ºæ—¥å¿—è®°å½•ï¼ˆä¸å†å­˜å‚¨toolså’Œmodelsï¼Œå› ä¸ºç°åœ¨åœ¨output_groupsä¸­ï¼‰
        log = GenLog(
            title=title,
            log_type=log_type,
            tools=None,  # ä¸å†åœ¨ä¸»è¡¨å­˜å‚¨
            models=None,  # ä¸å†åœ¨ä¸»è¡¨å­˜å‚¨
            prompt=prompt,
            params_note=params_note,
            comparison_group_id=None,  # ä¸å†ä½¿ç”¨å¯¹æ¯”ç»„åŠŸèƒ½
            is_nsfw=is_nsfw_value
        )
        db.add(log)
        db.flush()  # è·å– ID
        
        # å¤„ç†è¾“å…¥æ–‡ä»¶ï¼ˆä»… img2img æ¨¡å¼ï¼‰
        logger.info(f"åˆ›å»ºè®°å½• - log_type: {log_type}, input_filesæ•°é‡: {len(input_files) if input_files else 0}, input_filesç±»å‹: {type(input_files)}")
        if log_type == 'img2img' and input_files:
            logger.info(f"å¼€å§‹å¤„ç†è¾“å…¥æ–‡ä»¶ï¼Œæ•°é‡: {len(input_files)}")
            for idx, file in enumerate(input_files):
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()
                
                # éªŒè¯å›¾ç‰‡
                is_valid, error_msg = validate_image(content, file.filename)
                if not is_valid:
                    raise HTTPException(status_code=400, detail=f"è¾“å…¥å›¾ç‰‡éªŒè¯å¤±è´¥ ({file.filename}): {error_msg}")
                
                # ä¸Šä¼ åŸå›¾
                original_key = await rustfs_client.upload_file(
                    content,
                    file.filename,
                    file.content_type
                )
                if not original_key:
                    raise HTTPException(status_code=500, detail=f"ä¸Šä¼ è¾“å…¥å›¾ç‰‡å¤±è´¥: {file.filename}")
                
                # ç”Ÿæˆå¹¶ä¸Šä¼ ç¼©ç•¥å›¾
                try:
                    thumbnail_content, thumbnail_content_type = generate_thumbnail(content)
                    thumbnail_key = await rustfs_client.upload_file(
                        thumbnail_content,
                        f"thumb_{file.filename}",
                        thumbnail_content_type
                    )
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå›¾")
                    thumbnail_key = original_key
                
                # è·å–å¤‡æ³¨ï¼ˆå¦‚æœæœ‰ï¼‰
                note = input_notes_dict.get(file.filename, '')
                
                # åˆ›å»ºèµ„æºè®°å½•
                asset = LogAsset(
                    log_id=log.id,
                    file_key=original_key,
                    asset_type='input',
                    note=note,
                    sort_order=idx
                )
                db.add(asset)
                logger.info(f"å·²æ·»åŠ è¾“å…¥èµ„æºè®°å½•: file_key={original_key}, note={note}, sort_order={idx}")
        
        # å¤„ç†è¾“å‡ºç»„å’Œè¾“å‡ºæ–‡ä»¶
        file_index = 0
        for group_idx, group_data in enumerate(output_groups_list):
            # è§£æç»„çš„å·¥å…·å’Œæ¨¡å‹
            group_tools = group_data.get('tools', [])
            group_models = group_data.get('models', [])
            file_count = group_data.get('file_count', 0)
            
            # åˆ›å»ºè¾“å‡ºç»„
            output_group = OutputGroup(
                log_id=log.id,
                tools=group_tools if group_tools else None,
                models=group_models if group_models else None,
                sort_order=group_idx
            )
            db.add(output_group)
            db.flush()  # è·å–ç»„ID
            
            # å¤„ç†è¯¥ç»„çš„è¾“å‡ºæ–‡ä»¶
            for file_offset in range(file_count):
                if file_index >= len(output_files):
                    raise HTTPException(status_code=400, detail=f"è¾“å‡ºæ–‡ä»¶æ•°é‡ä¸è¶³ï¼šç»„ {group_idx + 1} éœ€è¦ {file_count} ä¸ªæ–‡ä»¶")
                
                file = output_files[file_index]
                file_index += 1
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()
                
                # éªŒè¯å›¾ç‰‡
                is_valid, error_msg = validate_image(content, file.filename)
                if not is_valid:
                    raise HTTPException(status_code=400, detail=f"è¾“å‡ºå›¾ç‰‡éªŒè¯å¤±è´¥ ({file.filename}): {error_msg}")
                
                # ä¸Šä¼ åŸå›¾
                original_key = await rustfs_client.upload_file(
                    content,
                    file.filename,
                    file.content_type
                )
                if not original_key:
                    raise HTTPException(status_code=500, detail=f"ä¸Šä¼ è¾“å‡ºå›¾ç‰‡å¤±è´¥: {file.filename}")
                
                # ç”Ÿæˆå¹¶ä¸Šä¼ ç¼©ç•¥å›¾
                try:
                    thumbnail_content, thumbnail_content_type = generate_thumbnail(content)
                    thumbnail_key = await rustfs_client.upload_file(
                        thumbnail_content,
                        f"thumb_{file.filename}",
                        thumbnail_content_type
                    )
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå›¾")
                    thumbnail_key = original_key
                
                # åˆ›å»ºèµ„æºè®°å½•ï¼Œå…³è”åˆ°è¾“å‡ºç»„
                asset = LogAsset(
                    log_id=log.id,
                    file_key=original_key,
                    asset_type='output',
                    output_group_id=output_group.id,
                    sort_order=file_offset
                )
                db.add(asset)
        
        # æäº¤äº‹åŠ¡
        db.commit()
        db.refresh(log)
        
        logger.info(f"åˆ›å»ºè®°å½•æˆåŠŸ: ID={log.id}, title={title}")
        
        # æ¸…é™¤ç›¸å…³ç¼“å­˜
        cache.clear("tags:")  # æ¸…é™¤æ ‡ç­¾ç›¸å…³ç¼“å­˜
        cache.clear("logs_")  # æ¸…é™¤åˆ—è¡¨ç¼“å­˜
        
        return {
            "id": log.id,
            "title": log.title,
            "log_type": log.log_type,
            "comparison_group_id": log.comparison_group_id,  # è¿”å›å¯¹æ¯”ç»„IDï¼Œç”¨äºåç»­è®°å½•åŠ å…¥
            "created_at": log.created_at.isoformat(),
            "is_nsfw": log.is_nsfw == 'true' if log.is_nsfw else False  # è½¬æ¢ä¸ºå¸ƒå°”å€¼
        }
        
    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"åˆ›å»ºè®°å½•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºè®°å½•å¤±è´¥: {str(e)}")


@router.get("/")
async def list_logs(
    page: int = 1,
    page_size: int = 20,
    search: Optional[str] = None,
    log_type: Optional[str] = None,
    tool: Optional[str] = None,
    model: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    è·å–è®°å½•åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰
    
    - **page**: é¡µç ï¼ˆä» 1 å¼€å§‹ï¼‰
    - **page_size**: æ¯é¡µæ•°é‡
    - **search**: æœç´¢æ ‡é¢˜å…³é”®è¯
    - **log_type**: ç­›é€‰ç±»å‹
    - **tool**: ç­›é€‰å·¥å…·æ ‡ç­¾
    - **model**: ç­›é€‰æ¨¡å‹æ ‡ç­¾
    """
    try:
        # æ„å»ºç¼“å­˜é”®
        cache_key = f"logs_list_{page}_{page_size}_{search or ''}_{log_type or ''}_{tool or ''}_{model or ''}"
        
        # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆç¼“å­˜1åˆ†é’Ÿï¼‰
        cached_result = cache.get(cache_key)
        if cached_result:
            logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
            return cached_result
        query = db.query(GenLog)
        
        # æ ‡é¢˜æœç´¢
        if search:
            query = query.filter(GenLog.title.ilike(f"%{search}%"))
        
        # ç±»å‹ç­›é€‰
        if log_type:
            query = query.filter(GenLog.log_type == log_type)
        
        # æ ‡ç­¾ç­›é€‰ï¼ˆä»è¾“å‡ºç»„è¡¨ç­›é€‰ï¼‰
        if tool:
            # ä½¿ç”¨ PostgreSQL çš„ ANY æ“ä½œç¬¦ï¼Œä½†éœ€è¦è½¬ä¹‰å•å¼•å·é˜²æ­¢ SQL æ³¨å…¥
            if all(c.isalnum() or c in ' ._-' for c in tool):
                from sqlalchemy import text
                tool_escaped = tool.replace("'", "''")
                # ä»è¾“å‡ºç»„è¡¨ç­›é€‰ï¼Œæˆ–ä»ä¸»è¡¨ç­›é€‰ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                query = query.filter(
                    text(f"""
                        EXISTS (
                            SELECT 1 FROM log_output_groups 
                            WHERE log_output_groups.log_id = gen_logs.id 
                            AND '{tool_escaped}' = ANY(log_output_groups.tools)
                        )
                        OR ('{tool_escaped}' = ANY(gen_logs.tools))
                    """)
                )
            else:
                query = query.filter(text("1=0"))
        
        if model:
            if all(c.isalnum() or c in ' ._-' for c in model):
                from sqlalchemy import text
                model_escaped = model.replace("'", "''")
                # ä»è¾“å‡ºç»„è¡¨ç­›é€‰ï¼Œæˆ–ä»ä¸»è¡¨ç­›é€‰ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                query = query.filter(
                    text(f"""
                        EXISTS (
                            SELECT 1 FROM log_output_groups 
                            WHERE log_output_groups.log_id = gen_logs.id 
                            AND '{model_escaped}' = ANY(log_output_groups.models)
                        )
                        OR ('{model_escaped}' = ANY(gen_logs.models))
                    """)
                )
            else:
                query = query.filter(text("1=0"))
        
        # æ’åºï¼šæœ€æ–°çš„åœ¨å‰
        query = query.order_by(desc(GenLog.created_at))
        
        # åˆ†é¡µ
        total = query.count()
        logs = query.offset((page - 1) * page_size).limit(page_size).all()
        
        # ä¼˜åŒ–ï¼šæ‰¹é‡æŸ¥è¯¢æ‰€æœ‰ç›¸å…³çš„ assets å’Œ output_groupsï¼Œé¿å… N+1 æŸ¥è¯¢
        log_ids = [log.id for log in logs]
        
        # æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰ output å›¾ç‰‡
        all_output_assets = db.query(LogAsset).filter(
            LogAsset.log_id.in_(log_ids),
            LogAsset.asset_type == 'output'
        ).order_by(LogAsset.sort_order).all()
        
        # æŒ‰ log_id åˆ†ç»„
        assets_by_log_id: dict[int, list] = {}
        for asset in all_output_assets:
            if asset.log_id not in assets_by_log_id:
                assets_by_log_id[asset.log_id] = []
            assets_by_log_id[asset.log_id].append(asset)
        
        # æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰è¾“å‡ºç»„
        all_output_groups = db.query(OutputGroup).filter(
            OutputGroup.log_id.in_(log_ids)
        ).order_by(OutputGroup.sort_order).all()
        
        # æŒ‰ log_id åˆ†ç»„
        groups_by_log_id: dict[int, list] = {}
        for group in all_output_groups:
            if group.log_id not in groups_by_log_id:
                groups_by_log_id[group.log_id] = []
            groups_by_log_id[group.log_id].append(group)
        
        # è·å–å°é¢å›¾å’Œè¾“å‡ºå›¾ç‰‡ä¿¡æ¯
        result = []
        for log in logs:
            # ä»æ‰¹é‡æŸ¥è¯¢çš„ç»“æœä¸­è·å–
            output_assets = assets_by_log_id.get(log.id, [])
            output_groups = groups_by_log_id.get(log.id, [])
            
            # åˆå¹¶æ‰€æœ‰ç»„çš„å·¥å…·å’Œæ¨¡å‹ï¼ˆå»é‡ï¼‰
            all_tools = set()
            all_models = set()
            for group in output_groups:
                if group.tools:
                    all_tools.update(group.tools)
                if group.models:
                    all_models.update(group.models)
            
            # å¦‚æœæ²¡æœ‰è¾“å‡ºç»„ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰ï¼Œä»ä¸»è¡¨è·å–
            if not output_groups and log.tools:
                all_tools.update(log.tools)
            if not output_groups and log.models:
                all_models.update(log.models)
            
            # ç”Ÿæˆå°é¢å›¾ URLï¼ˆç¬¬ä¸€å¼ å›¾ç‰‡ï¼‰å’Œå¤šå¼ å›¾ç‰‡çš„é¢„è§ˆ URL
            cover_url = None
            preview_urls: list[str] = []
            
            # è·å–å‰å‡ å¼ å›¾ç‰‡çš„ URLï¼ˆæœ€å¤š4å¼ ï¼Œç”¨äºé¢„è§ˆï¼‰
            # ä½¿ç”¨ API ä»£ç† URLï¼Œè¿™æ ·å¤–ç½‘å¯ä»¥é€šè¿‡ web ç«¯å£è®¿é—®
            # åˆ—è¡¨æ˜¾ç¤ºä½¿ç”¨ä¸­ç­‰å°ºå¯¸å›¾ç‰‡ï¼ˆ1920pxï¼Œè´¨é‡85%ï¼‰ï¼Œå‡å°‘ä¼ è¾“é‡
            for asset in output_assets[:4]:
                url = get_proxy_url(asset.file_key, size='medium')  # ä½¿ç”¨ä¸­ç­‰å°ºå¯¸ï¼Œå‡å°‘ä¼ è¾“é‡
                preview_urls.append(url)
                if not cover_url:  # ç¬¬ä¸€å¼ ä½œä¸ºå°é¢
                    cover_url = url
            
            result.append({
                "id": log.id,
                "title": log.title,
                "log_type": log.log_type,
                "tools": list(all_tools),  # æ‰€æœ‰ç»„çš„å·¥å…·åˆå¹¶
                "models": list(all_models),  # æ‰€æœ‰ç»„çš„æ¨¡å‹åˆå¹¶
                "cover_url": cover_url,
                "output_count": len(output_assets),  # è¾“å‡ºå›¾ç‰‡æ€»æ•°
                "preview_urls": preview_urls,  # å‰å‡ å¼ é¢„è§ˆå›¾ï¼ˆæœ€å¤š4å¼ ï¼‰
                "created_at": log.created_at.isoformat(),
                "is_nsfw": log.is_nsfw == 'true' if log.is_nsfw else False  # è½¬æ¢ä¸ºå¸ƒå°”å€¼
            })
        
        result_data = {
            "total": total,
            "page": page,
            "page_size": page_size,
            "items": result
        }
        
        # ç¼“å­˜ç»“æœï¼ˆ1åˆ†é’Ÿï¼‰
        cache.set(cache_key, result_data, 60)
        
        return result_data
        
    except Exception as e:
        logger.error(f"è·å–è®°å½•åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/{log_id}")
async def get_log(log_id: int, db: Session = Depends(get_db)):
    """
    è·å–å•æ¡è®°å½•è¯¦æƒ…
    """
    try:
        log = db.query(GenLog).filter(GenLog.id == log_id).first()
        if not log:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        # è·å–å…³è”çš„èµ„æº
        assets = db.query(LogAsset).filter(
            LogAsset.log_id == log_id
        ).order_by(LogAsset.sort_order).all()
        
        logger.info(f"è·å–è®°å½•è¯¦æƒ… - log_id: {log_id}, æ€»èµ„æºæ•°: {len(assets)}")
        for asset in assets:
            logger.info(f"èµ„æº: id={asset.id}, asset_type={asset.asset_type}, file_key={asset.file_key}")
        
        # åˆ†ç¦»è¾“å…¥èµ„æº
        input_assets = []
        for asset in assets:
            if asset.asset_type == 'input':
                # ä½¿ç”¨ API ä»£ç† URL
                asset_url = get_proxy_url(asset.file_key)
                
                input_assets.append({
                    "id": asset.id,
                    "file_key": asset.file_key,
                    "url": asset_url,
                    "note": asset.note,
                    "sort_order": asset.sort_order
                })
        
        # è·å–è¾“å‡ºç»„å¹¶æŒ‰ç»„ç»„ç»‡è¾“å‡ºå›¾ç‰‡
        output_groups_data = []
        output_groups = db.query(OutputGroup).filter(
            OutputGroup.log_id == log_id
        ).order_by(OutputGroup.sort_order).all()
        
        for group in output_groups:
            # è·å–è¯¥ç»„çš„è¾“å‡ºå›¾ç‰‡
            group_assets = db.query(LogAsset).filter(
                LogAsset.log_id == log_id,
                LogAsset.asset_type == 'output',
                LogAsset.output_group_id == group.id
            ).order_by(LogAsset.sort_order).all()
            
            group_output_assets = []
            for asset in group_assets:
                # ä½¿ç”¨ API ä»£ç† URL
                asset_url = get_proxy_url(asset.file_key)
                
                group_output_assets.append({
                    "id": asset.id,
                    "file_key": asset.file_key,
                    "url": asset_url,
                    "sort_order": asset.sort_order
                })
            
            output_groups_data.append({
                "id": group.id,
                "tools": group.tools or [],
                "models": group.models or [],
                "assets": group_output_assets
            })
        
        # å¦‚æœæ²¡æœ‰è¾“å‡ºç»„ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰ï¼Œå°†æ‰€æœ‰è¾“å‡ºå›¾ç‰‡æ”¾åœ¨ä¸€ä¸ªé»˜è®¤ç»„ä¸­
        if not output_groups_data:
            all_output_assets = db.query(LogAsset).filter(
                LogAsset.log_id == log_id,
                LogAsset.asset_type == 'output'
            ).order_by(LogAsset.sort_order).all()
            
            if all_output_assets:
                default_group_assets = []
                for asset in all_output_assets:
                    # ä½¿ç”¨ API ä»£ç† URL
                    asset_url = get_proxy_url(asset.file_key)
                    
                    default_group_assets.append({
                        "id": asset.id,
                        "file_key": asset.file_key,
                        "url": asset_url,
                        "sort_order": asset.sort_order
                    })
                
                # ä»ä¸»è¡¨è·å–å·¥å…·å’Œæ¨¡å‹ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                output_groups_data.append({
                    "id": None,
                    "tools": log.tools or [],
                    "models": log.models or [],
                    "assets": default_group_assets
                })
        
        logger.info(f"è¿”å›è¯¦æƒ… - input_assetsæ•°é‡: {len(input_assets)}, output_groupsæ•°é‡: {len(output_groups_data)}")
        
        return {
            "id": log.id,
            "title": log.title,
            "log_type": log.log_type,
            "prompt": log.prompt if log.prompt else None,
            "params_note": log.params_note if log.params_note else None,
            "input_assets": input_assets,
            "output_groups": output_groups_data,  # æŒ‰è¾“å‡ºç»„ç»„ç»‡çš„å›¾ç‰‡
            "created_at": log.created_at.isoformat(),
            "is_nsfw": log.is_nsfw == 'true' if log.is_nsfw else False  # è½¬æ¢ä¸ºå¸ƒå°”å€¼
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–è®°å½•è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.put("/{log_id}")
async def update_log(
    log_id: int,
    title: str = Form(...),
    log_type: str = Form(...),
    prompt: Optional[str] = Form(None),
    params_note: Optional[str] = Form(None),
    is_nsfw: Optional[str] = Form(None, description="æ˜¯å¦ä¸ºNSFWå†…å®¹ï¼Œ'true' æˆ– 'false'"),
    current_user: User = Depends(require_permission("log.edit")),
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°è®°å½•ï¼ˆä»…æ›´æ–°å…ƒæ•°æ®ï¼Œä¸åŒ…æ‹¬å›¾ç‰‡å’Œè¾“å‡ºç»„ï¼‰
    
    - **title**: æ ‡é¢˜ï¼ˆå¿…å¡«ï¼‰
    - **log_type**: ç±»å‹ï¼Œ'txt2img' æˆ– 'img2img'ï¼ˆå¿…å¡«ï¼‰
    - **prompt**: æç¤ºè¯
    - **params_note**: å‚æ•°è®°å½•
    """
    try:
        # éªŒè¯ç±»å‹
        if log_type not in ('txt2img', 'img2img'):
            raise HTTPException(status_code=400, detail="log_type å¿…é¡»æ˜¯ 'txt2img' æˆ– 'img2img'")
        
        # æŸ¥æ‰¾è®°å½•
        log = db.query(GenLog).filter(GenLog.id == log_id).first()
        if not log:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        # å¤„ç†is_nsfwå‚æ•°
        if is_nsfw is not None:
            log.is_nsfw = 'true' if is_nsfw.lower() == 'true' else 'false'
        
        # æ›´æ–°è®°å½•ï¼ˆä¸å†æ›´æ–°toolså’Œmodelsï¼Œå› ä¸ºç°åœ¨åœ¨output_groupsä¸­ï¼‰
        log.title = title
        log.log_type = log_type
        log.prompt = prompt if prompt and prompt.strip() else None
        log.params_note = params_note if params_note and params_note.strip() else None
        
        db.commit()
        db.refresh(log)
        
        logger.info(f"æ›´æ–°è®°å½•æˆåŠŸ: ID={log_id}, title={title}")
        
        # æ¸…é™¤ç›¸å…³ç¼“å­˜
        cache.clear("tags:")  # æ¸…é™¤æ ‡ç­¾ç›¸å…³ç¼“å­˜
        cache.clear("logs_")  # æ¸…é™¤åˆ—è¡¨ç¼“å­˜
        
        return {
            "id": log.id,
            "title": log.title,
            "log_type": log.log_type,
            "prompt": log.prompt,
            "params_note": log.params_note,
            "created_at": log.created_at.isoformat(),
            "is_nsfw": log.is_nsfw == 'true' if log.is_nsfw else False  # è½¬æ¢ä¸ºå¸ƒå°”å€¼
        }
        
    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"æ›´æ–°è®°å½•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°è®°å½•å¤±è´¥: {str(e)}")


@router.delete("/{log_id}")
async def delete_log(
    log_id: int,
    current_user: User = Depends(require_permission("log.delete")),
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤è®°å½•åŠå…¶å…³è”çš„æ‰€æœ‰èµ„æºï¼ˆåŒ…æ‹¬å›¾ç‰‡æ–‡ä»¶ï¼‰
    """
    try:
        # æŸ¥æ‰¾è®°å½•
        log = db.query(GenLog).filter(GenLog.id == log_id).first()
        if not log:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        # è·å–æ‰€æœ‰å…³è”çš„èµ„æº
        assets = db.query(LogAsset).filter(LogAsset.log_id == log_id).all()
        
        # åˆ é™¤ S3 ä¸­çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬åŸå›¾å’Œç¼©ç•¥å›¾ï¼‰
        deleted_files = []
        failed_files = []
        
        for asset in assets:
            # åˆ é™¤åŸå›¾
            if asset.file_key:
                success = await rustfs_client.delete_file(asset.file_key)
                if success:
                    deleted_files.append(asset.file_key)
                else:
                    failed_files.append(asset.file_key)
            
            # å°è¯•åˆ é™¤ç¼©ç•¥å›¾ï¼ˆç¼©ç•¥å›¾ key æ ¼å¼å¯èƒ½æ˜¯ thumb_xxx æˆ–ä»åŸå›¾ key æ¨å¯¼ï¼‰
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦çŸ¥é“ç¼©ç•¥å›¾çš„ keyï¼Œä½†å½“å‰è®¾è®¡ä¸­ç¼©ç•¥å›¾æ˜¯å•ç‹¬å­˜å‚¨çš„
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªåˆ é™¤åŸå›¾ï¼Œç¼©ç•¥å›¾å¯ä»¥åç»­æ¸…ç†
            # TODO: å¦‚æœéœ€è¦ç²¾ç¡®åˆ é™¤ç¼©ç•¥å›¾ï¼Œéœ€è¦åœ¨ LogAsset ä¸­æ·»åŠ  thumbnail_key å­—æ®µ
        
        # åˆ é™¤æ•°æ®åº“è®°å½•ï¼ˆçº§è”åˆ é™¤ LogAssetï¼‰
        db.delete(log)
        db.commit()
        
        logger.info(f"åˆ é™¤è®°å½•æˆåŠŸ: ID={log_id}, åˆ é™¤æ–‡ä»¶: {len(deleted_files)}, å¤±è´¥: {len(failed_files)}")
        
        # æ¸…é™¤ç›¸å…³ç¼“å­˜
        cache.clear("tags:")  # æ¸…é™¤æ ‡ç­¾ç›¸å…³ç¼“å­˜
        cache.clear("logs_")  # æ¸…é™¤åˆ—è¡¨ç¼“å­˜
        
        if failed_files:
            logger.warning(f"éƒ¨åˆ†æ–‡ä»¶åˆ é™¤å¤±è´¥: {failed_files}")
        
        return {
            "id": log_id,
            "message": "åˆ é™¤æˆåŠŸ",
            "deleted_files": len(deleted_files),
            "failed_files": len(failed_files)
        }
        
    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"åˆ é™¤è®°å½•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤è®°å½•å¤±è´¥: {str(e)}")


@router.post("/{log_id}/output-groups")
async def add_output_group(
    log_id: int,
    tools: Optional[str] = Form(None),
    models: Optional[str] = Form(None),
    output_files: List[UploadFile] = File(..., description="è¾“å‡ºå›¾ç‰‡æ–‡ä»¶"),
    current_user: User = Depends(require_permission("log.edit")),
    db: Session = Depends(get_db)
):
    """
    ä¸ºç°æœ‰è®°å½•æ·»åŠ æ–°çš„è¾“å‡ºç»„
    
    - **tools**: å·¥å…·æ ‡ç­¾ï¼Œé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    - **models**: æ¨¡å‹æ ‡ç­¾ï¼Œé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    - **output_files**: è¾“å‡ºå›¾ç‰‡æ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰
    """
    try:
        # æŸ¥æ‰¾è®°å½•
        log = db.query(GenLog).filter(GenLog.id == log_id).first()
        if not log:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        # è§£ææ ‡ç­¾
        tools_list = [t.strip() for t in tools.split(',') if t.strip()] if tools else []
        models_list = [m.strip() for m in models.split(',') if m.strip()] if models else []
        
        # è·å–å½“å‰æœ€å¤§çš„sort_order
        max_sort_order_result = db.query(OutputGroup.sort_order).filter(
            OutputGroup.log_id == log_id
        ).order_by(OutputGroup.sort_order.desc()).first()
        next_sort_order = (max_sort_order_result[0] + 1) if max_sort_order_result else 0
        
        # åˆ›å»ºè¾“å‡ºç»„
        output_group = OutputGroup(
            log_id=log.id,
            tools=tools_list if tools_list else None,
            models=models_list if models_list else None,
            sort_order=next_sort_order
        )
        db.add(output_group)
        db.flush()  # è·å–ç»„ID
        
        # å¤„ç†è¾“å‡ºæ–‡ä»¶
        for idx, file in enumerate(output_files):
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = await file.read()
            
            # éªŒè¯å›¾ç‰‡
            is_valid, error_msg = validate_image(content, file.filename)
            if not is_valid:
                raise HTTPException(status_code=400, detail=f"è¾“å‡ºå›¾ç‰‡éªŒè¯å¤±è´¥ ({file.filename}): {error_msg}")
            
            # ä¸Šä¼ åŸå›¾
            original_key = await rustfs_client.upload_file(
                content,
                file.filename,
                file.content_type
            )
            if not original_key:
                raise HTTPException(status_code=500, detail=f"ä¸Šä¼ è¾“å‡ºå›¾ç‰‡å¤±è´¥: {file.filename}")
            
            # ç”Ÿæˆå¹¶ä¸Šä¼ ç¼©ç•¥å›¾
            try:
                thumbnail_content, thumbnail_content_type = generate_thumbnail(content)
                thumbnail_key = await rustfs_client.upload_file(
                    thumbnail_content,
                    f"thumb_{file.filename}",
                    thumbnail_content_type
                )
            except Exception as e:
                logger.warning(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå›¾")
                thumbnail_key = original_key
            
            # åˆ›å»ºèµ„æºè®°å½•ï¼Œå…³è”åˆ°è¾“å‡ºç»„
            asset = LogAsset(
                log_id=log.id,
                file_key=original_key,
                asset_type='output',
                output_group_id=output_group.id,
                sort_order=idx
            )
            db.add(asset)
        
        # æäº¤äº‹åŠ¡
        db.commit()
        db.refresh(output_group)
        
        logger.info(f"æ·»åŠ è¾“å‡ºç»„æˆåŠŸ: log_id={log_id}, group_id={output_group.id}")
        
        return {
            "id": output_group.id,
            "log_id": log.id,
            "tools": output_group.tools or [],
            "models": output_group.models or [],
            "file_count": len(output_files),
            "created_at": output_group.created_at.isoformat()
        }
        
    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"æ·»åŠ è¾“å‡ºç»„å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ·»åŠ è¾“å‡ºç»„å¤±è´¥: {str(e)}")


@router.put("/{log_id}/output-groups/{group_id}")
async def update_output_group(
    log_id: int,
    group_id: int,
    tools: Optional[str] = Form(None),
    models: Optional[str] = Form(None),
    remove_asset_ids: Optional[str] = Form(None, description="è¦åˆ é™¤çš„å›¾ç‰‡IDåˆ—è¡¨ï¼ŒJSONæ ¼å¼ï¼š[1, 2, 3]"),
    output_files: List[UploadFile] = File(default=[]),
    current_user: User = Depends(require_permission("log.edit")),
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°è¾“å‡ºç»„ï¼ˆä¿®æ”¹å·¥å…·ã€æ¨¡å‹ï¼Œæ·»åŠ æˆ–åˆ é™¤å›¾ç‰‡ï¼‰
    
    - **tools**: å·¥å…·æ ‡ç­¾ï¼Œé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    - **models**: æ¨¡å‹æ ‡ç­¾ï¼Œé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    - **remove_asset_ids**: è¦åˆ é™¤çš„å›¾ç‰‡IDåˆ—è¡¨ï¼ŒJSONæ ¼å¼
    - **output_files**: æ–°å¢çš„è¾“å‡ºå›¾ç‰‡æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    """
    try:
        # æŸ¥æ‰¾è®°å½•å’Œè¾“å‡ºç»„
        log = db.query(GenLog).filter(GenLog.id == log_id).first()
        if not log:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        output_group = db.query(OutputGroup).filter(
            OutputGroup.id == group_id,
            OutputGroup.log_id == log_id
        ).first()
        if not output_group:
            raise HTTPException(status_code=404, detail="è¾“å‡ºç»„ä¸å­˜åœ¨")
        
        # æ›´æ–°å·¥å…·å’Œæ¨¡å‹
        if tools is not None:
            if tools.strip() == '':
                output_group.tools = None
            else:
                tools_list = [t.strip() for t in tools.split(',') if t.strip()]
                output_group.tools = tools_list if tools_list else None
        if models is not None:
            if models.strip() == '':
                output_group.models = None
            else:
                models_list = [m.strip() for m in models.split(',') if m.strip()]
                output_group.models = models_list if models_list else None
        
        # åˆ é™¤æŒ‡å®šçš„å›¾ç‰‡
        if remove_asset_ids:
            import json
            try:
                asset_ids_to_remove = json.loads(remove_asset_ids)
                if isinstance(asset_ids_to_remove, list):
                    assets_to_remove = db.query(LogAsset).filter(
                        LogAsset.id.in_(asset_ids_to_remove),
                        LogAsset.output_group_id == group_id,
                        LogAsset.log_id == log_id
                    ).all()
                    
                    for asset in assets_to_remove:
                        # åˆ é™¤S3ä¸­çš„æ–‡ä»¶
                        try:
                            await rustfs_client.delete_file(asset.file_key)
                        except Exception as e:
                            logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {asset.file_key}, {e}")
                        
                        db.delete(asset)
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="remove_asset_ids å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ•°ç»„")
        
        # æ·»åŠ æ–°çš„å›¾ç‰‡
        current_max_sort = db.query(LogAsset.sort_order).filter(
            LogAsset.output_group_id == group_id
        ).order_by(LogAsset.sort_order.desc()).first()
        next_sort_order = (current_max_sort[0] + 1) if current_max_sort else 0
        
        for idx, file in enumerate(output_files):
            content = await file.read()
            
            is_valid, error_msg = validate_image(content, file.filename)
            if not is_valid:
                raise HTTPException(status_code=400, detail=f"è¾“å‡ºå›¾ç‰‡éªŒè¯å¤±è´¥ ({file.filename}): {error_msg}")
            
            original_key = await rustfs_client.upload_file(
                content,
                file.filename,
                file.content_type
            )
            if not original_key:
                raise HTTPException(status_code=500, detail=f"ä¸Šä¼ è¾“å‡ºå›¾ç‰‡å¤±è´¥: {file.filename}")
            
            try:
                thumbnail_content = generate_thumbnail(content)
                thumbnail_key = await rustfs_client.upload_file(
                    thumbnail_content,
                    f"thumb_{file.filename}",
                    "image/jpeg"
                )
            except Exception as e:
                logger.warning(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå›¾")
                thumbnail_key = original_key
            
            asset = LogAsset(
                log_id=log.id,
                file_key=original_key,
                asset_type='output',
                output_group_id=output_group.id,
                sort_order=next_sort_order + idx
            )
            db.add(asset)
        
        db.commit()
        db.refresh(output_group)
        
        logger.info(f"æ›´æ–°è¾“å‡ºç»„æˆåŠŸ: log_id={log_id}, group_id={group_id}")
        
        # æ¸…é™¤ç›¸å…³ç¼“å­˜
        cache.clear("tags:")  # æ¸…é™¤æ ‡ç­¾ç›¸å…³ç¼“å­˜
        cache.clear("logs_")  # æ¸…é™¤åˆ—è¡¨ç¼“å­˜
        
        return {
            "id": output_group.id,
            "log_id": log.id,
            "tools": output_group.tools or [],
            "models": output_group.models or [],
            "created_at": output_group.created_at.isoformat()
        }
        
    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"æ›´æ–°è¾“å‡ºç»„å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°è¾“å‡ºç»„å¤±è´¥: {str(e)}")


@router.delete("/{log_id}/output-groups/{group_id}")
async def delete_output_group(
    log_id: int,
    group_id: int,
    current_user: User = Depends(require_permission("log.delete")),
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤è¾“å‡ºç»„åŠå…¶å…³è”çš„æ‰€æœ‰å›¾ç‰‡
    """
    try:
        # æŸ¥æ‰¾è®°å½•å’Œè¾“å‡ºç»„
        log = db.query(GenLog).filter(GenLog.id == log_id).first()
        if not log:
            raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
        
        output_group = db.query(OutputGroup).filter(
            OutputGroup.id == group_id,
            OutputGroup.log_id == log_id
        ).first()
        if not output_group:
            raise HTTPException(status_code=404, detail="è¾“å‡ºç»„ä¸å­˜åœ¨")
        
        # è·å–è¯¥ç»„çš„æ‰€æœ‰å›¾ç‰‡
        assets = db.query(LogAsset).filter(
            LogAsset.output_group_id == group_id,
            LogAsset.log_id == log_id
        ).all()
        
        # åˆ é™¤S3ä¸­çš„æ–‡ä»¶
        for asset in assets:
            try:
                await rustfs_client.delete_file(asset.file_key)
            except Exception as e:
                logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {asset.file_key}, {e}")
        
        # åˆ é™¤è¾“å‡ºç»„ï¼ˆçº§è”åˆ é™¤ä¼šåŒæ—¶åˆ é™¤å…³è”çš„assetsï¼‰
        db.delete(output_group)
        db.commit()
        
        logger.info(f"åˆ é™¤è¾“å‡ºç»„æˆåŠŸ: log_id={log_id}, group_id={group_id}")
        
        # æ¸…é™¤ç›¸å…³ç¼“å­˜
        cache.clear("tags:")  # æ¸…é™¤æ ‡ç­¾ç›¸å…³ç¼“å­˜
        cache.clear("logs_")  # æ¸…é™¤åˆ—è¡¨ç¼“å­˜
        
        return {"message": "è¾“å‡ºç»„å·²åˆ é™¤"}
        
    except HTTPException:
        db.rollback()
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"åˆ é™¤è¾“å‡ºç»„å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤è¾“å‡ºç»„å¤±è´¥: {str(e)}")

